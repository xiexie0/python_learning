{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43ae063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /usr3/graduate/jack7z/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d5bfa",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is the field of computer science focused on enabling computers to understand, analyze, and generate human language. The evolution of NLP can be categorized into three major eras: symbolic, statistical, and neural. The advancements made in each era continue to be relevant and valuable today. In this lecture, we explore one tool in each era that can be useful in your research. We start with regular expression, a symbolic NLP tool. The first example is the match function, which finds the first match in a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3292947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eg 1 \n",
    "# pattern = \"^The.*Spain$\"\n",
    "# pattern = \"The.*Spain\"\n",
    "pattern = \"The.*?Spain\"\n",
    "\n",
    "txt1 = \"The rain in Spain\"\n",
    "txt2 = 'Yes, indeed. The rain in Spain is precious. Yes, indeed. The people in Spain speak Spanish.'\n",
    "txt3 = \"The inflammation causes pains\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "798a0b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first white-space character is located in position: 4\n"
     ]
    }
   ],
   "source": [
    "#Eg 1.5\n",
    "\n",
    "x = re.search(\"\\s\", txt2)\n",
    "print(\"The first white-space character is located in position:\", x.start())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6284d3",
   "metadata": {},
   "source": [
    "As is shown in the example above, re.match() finds the first match in a string and stops. If we want to find multiple matches in a string, you can use re.findall() instead. It returns a list of all non-overlapping matches of the pattern in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224f63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eg 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a16117",
   "metadata": {},
   "source": [
    "Just as another example, re.findall() can be used to search for numbers, and much more if we have the correct expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2ecfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n"
     ]
    }
   ],
   "source": [
    "#Eg 3\n",
    "\n",
    "pattern = r'\\d+'  # This pattern matches one or more digits\n",
    "\n",
    "text = \"I have 10 apples and 5 oranges.\"\n",
    "\n",
    "# Print all the matches\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "pattern = r'\\d+\\s+\\w+' # This pattern matches one or more digits, followed by one or more space, followed by one or more letters\n",
    "# pattern = r'(\\d+)\\s+(\\w+)' # This pattern matches one or more digits, followed by one or more space, followed by one or more letters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228282c3",
   "metadata": {},
   "source": [
    "And we can revise the strings using re.sub(). For example, suppose we need to convert from inch to cm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "672af1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eg 4\n",
    "\n",
    "\n",
    "text = \"The height, width, and depth of these 6 identical boxes are 10 inches, 19 inches, and 8 inches respectively.\"\n",
    "\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a2714",
   "metadata": {},
   "source": [
    "re is a powerful tool in machine learning. Here are a few examples:\n",
    "\n",
    "1. Text Preprocessing: Regular expressions are commonly used for text cleaning and preprocessing tasks. They can help remove or replace specific patterns, such as URLs, email addresses, special characters, or punctuation marks. This can be useful for improving the quality of input data before training an ML model.\n",
    "\n",
    "2. Feature Extraction: Regular expressions can be employed to extract specific patterns or features from text data. For instance, you can use regex to identify and extract dates, phone numbers, or specific keywords from a document. These extracted features can then be used as inputs to an ML model.\n",
    "\n",
    "3. Text Classification: Regular expressions can aid in creating rules or patterns for text classification tasks. For example, you can define regex patterns to identify certain types of documents or topics based on specific keywords or patterns present in the text. These patterns can be used as features to train a classification model.\n",
    "\n",
    "4. Named Entity Recognition (NER): NER is a task that involves identifying and classifying named entities (such as person names, locations, or organizations) in text. Regular expressions can be utilized to define patterns that match specific types of named entities and extract them from the text.\n",
    "\n",
    "5. Text Generation and Language Modeling: Regular expressions can be helpful in generating or manipulating text data. They can be used to define rules for generating text based on specific patterns or templates. For example, you can use regex to replace placeholders in a text template with dynamically generated content.\n",
    "\n",
    "There are more tool in regular expressions. Check out https://docs.python.org/3/howto/regex.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07823b34",
   "metadata": {},
   "source": [
    "Symbolic NLP are very useful. However, they are still very rigid. To increase the flexibility of processing natural languages, statistical NLP was developed. We will look at one example of statistical NLP method, namely using Bayesian statistics to classify sentences into positive and negative categories. To do so, we need to tokenize our input. Here is an example of tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb69e104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Life': True,\n",
       " 'is': True,\n",
       " 'beautiful': True,\n",
       " 'so': True,\n",
       " 'enjoy': True,\n",
       " 'everymoment': True,\n",
       " 'you': True,\n",
       " 'have': True,\n",
       " '.': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_sentence(sent):\n",
    "    return({word: True for word in nltk.word_tokenize(sent)})\n",
    "\n",
    "format_sentence(\"Life is beautiful so enjoy everymoment you have.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74285ca",
   "metadata": {},
   "source": [
    "Now we download some training and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6540138",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "with open(\"./pos_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        pos.append([format_sentence(i), 'pos'])\n",
    "        \n",
    "neg = []\n",
    "with open(\"./neg_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        neg.append([format_sentence(i), 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abeea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive example\n",
      "\"@Lakers ready to win tonight!!! \"\n",
      "\n",
      "Tokenized\n",
      "[{'``': True, '@': True, 'Lakers': True, 'ready': True, 'to': True, 'win': True, 'tonight': True, '!': True}, 'pos']\n",
      "\n",
      "============================\n",
      "\n",
      "Negative example\n",
      "\"@hillaryrachel oh i know how you feel. i took a leap of faith and asked Taylor Swift to be my BFFL ... she didnt reply \"\n",
      "\n",
      "Tokenized\n",
      "[{'``': True, '@': True, 'hillaryrachel': True, 'oh': True, 'i': True, 'know': True, 'how': True, 'you': True, 'feel': True, '.': True, 'took': True, 'a': True, 'leap': True, 'of': True, 'faith': True, 'and': True, 'asked': True, 'Taylor': True, 'Swift': True, 'to': True, 'be': True, 'my': True, 'BFFL': True, '...': True, 'she': True, 'didnt': True, 'reply': True}, 'neg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eg_num = 138\n",
    "\n",
    "print('Positive example')\n",
    "\n",
    "with open(\"./pos_tweets.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines[eg_num])\n",
    "print('Tokenized')\n",
    "\n",
    "print(pos[eg_num])\n",
    "\n",
    "print('\\n============================\\n')\n",
    "\n",
    "print('Negative example')\n",
    "\n",
    "with open(\"./neg_tweets.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines[eg_num])\n",
    "print('Tokenized')\n",
    "print(neg[eg_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47164fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train (90%) test (10%) split\n",
    "\n",
    "training = pos[:int((.9)*len(pos))] + neg[:int((.9)*len(neg))]\n",
    "test = pos[int((.1)*len(pos)):] + neg[int((.1)*len(neg)):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3e9d3",
   "metadata": {},
   "source": [
    "Here we train the a Naive Baye's classifier . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1136527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c600b569",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "457cc5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      no = True              neg : pos    =     21.2 : 1.0\n",
      "                 awesome = True              pos : neg    =     18.7 : 1.0\n",
      "                headache = True              neg : pos    =     18.3 : 1.0\n",
      "               beautiful = True              pos : neg    =     14.2 : 1.0\n",
      "                    love = True              pos : neg    =     14.2 : 1.0\n",
      "                      Hi = True              pos : neg    =     12.7 : 1.0\n",
      "                   Thank = True              pos : neg    =      9.7 : 1.0\n",
      "                     fan = True              pos : neg    =      9.7 : 1.0\n",
      "                    glad = True              pos : neg    =      9.7 : 1.0\n",
      "                    been = True              neg : pos    =      9.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd22f80",
   "metadata": {},
   "source": [
    "We can do some testing on the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f830e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "example1 = \"This workshop is likely going to prepare the students for their upcoming projects.\"\n",
    "example2 = \"Students need far more than this workshop to get prepared for real life questions.\"\n",
    "\n",
    "print(classifier.classify(format_sentence(example1)))\n",
    "print(classifier.classify(format_sentence(example2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b10894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is\n",
      "0.9562326869806094\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy on the test set is')\n",
    "print(accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c1cae",
   "metadata": {},
   "source": [
    "The accuracy is in fact not the most informative metric to look at. Better alternatives are the precision and recall. \n",
    "\n",
    "precision = true_positives / predicted_positives <br>\n",
    "recall = true_positives / actual_positives\n",
    "\n",
    "In this case, our precision is low, meaning many negative examples are marked as positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4d60ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981636060100167\n",
      "0.9676258992805755\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "predictions = [classifier.classify(features) for features, _ in test]\n",
    "ground_truth = [label for _, label in test]\n",
    "\n",
    "true_positives = sum(1 for pred, truth in zip(predictions, ground_truth) if pred == 'pos' and truth == 'pos')\n",
    "predicted_positives = sum(1 for pred in predictions if pred == 'pos')\n",
    "actual_positives = sum(1 for truth in ground_truth if truth == 'pos')\n",
    "\n",
    "precision = true_positives / predicted_positives\n",
    "recall = true_positives / actual_positives\n",
    "\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c285b",
   "metadata": {},
   "source": [
    "Neural NLP: ChatGPT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
